{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CACTUS Week 1\n",
    "## Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code thanks to https://python.plainenglish.io/using-python-and-twitter-api-2-to-get-user-details-437e442b4be9\n",
    "\n",
    "\n",
    "# For sending GET requests from the API\n",
    "import requests\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "# For saving the response data in CSV format\n",
    "import csv\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "#To add wait time between requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To be able to send your first request to the Twitter API, you need to have a developer account.\n",
    "2. Next, create a project and connect an App through the developer portal.\n",
    "3. Go to the developer portal dashboard\n",
    "4. Sign in with your developer account\n",
    "5. Create a new project, give it a name, a use-case based on the goal you want to achieve, and a description.\n",
    "6. If everything is successful, you should be able to see a page containing your keys and tokens, we will use one of these to access the API. Look out for the BEARER TOKEN. See https://miro.medium.com/max/2400/1*Y20zm9Vf1k5uRMRTMkHRkQ.png\n",
    "\n",
    "7. The next step is to create an auth() function that will have the ‚ÄúBearer Token‚Äù from the app we just created.\n",
    "8. Since this Bearer Token is sensitive information, you should not be sharing it with anyone at all. If you are working with a team you don‚Äôt want anyone to have access to it.\n",
    "9. So, we will save the token in an ‚Äúenvironment variable‚Äù.\n",
    "10. Finally, we will create our auth() function, which retrieves the token from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKEN'] = ''\n",
    "def auth():\n",
    "    return os.getenv('TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Headers\n",
    "Next, we will define a function that will take our bearer token, pass it for authorization and return headers we will use to access the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2UserLookupPython\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create URL\n",
    "Now that we can access the API, we will build the request for the endpoint we are going to use and the parameters we want to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(keyword):\n",
    "    \n",
    "    search_url = \"https://api.twitter.com/2/users/\" #Change to the endpoint you want to collect data from\n",
    "    # https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "                    'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "\n",
    "def create_url(user_names_list, user_fields ):\n",
    "    # Specify the usernames that you want to lookup below\n",
    "    # You can enter up to 100 comma-separated values.\n",
    "    user_names = ','.join(user_names_list) if len(user_names_list)>1 else user_names_list[0]\n",
    "    \n",
    "    usernames = f\"usernames={user_names}\"\n",
    "    url = \"https://api.twitter.com/2/users/by?{}&{}\".format(usernames, user_fields)\n",
    "    print(url)\n",
    "    return url\n",
    "\n",
    "def create_url_id(id):\n",
    "    url = \"https://api.twitter.com/2/users/{}/tweets\".format(id)\n",
    "    print(url)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defined function above contains two pieces:\n",
    "\n",
    "## search_url:\n",
    "\n",
    "Which is the link of the \"endpoint\" we want to access. Endpoint just means.. what we want to do with it. E.g.: if we want all the posts by a user, the endpoint is \"user lookup\"\n",
    "\n",
    "Twitter‚Äôs API has a lot of different endpoints. You can look them up here: https://miro.medium.com/max/700/1*1oJExGGK151WfQJ6LIikww.png\n",
    "\n",
    "Right now, this code is written for the full-archive search endpoint.\n",
    "\n",
    "## query_params:\n",
    "\n",
    "The parameters that the endpoint offers and we can use to customize the request we want to send. E.g.: if we want all the posts by a user, the endpoint is \"user lookup\", and the query parameter is the screen name of the user.\n",
    "\n",
    "1. Some parameters control the returned response\n",
    "```usernames={user_names}```\n",
    "\n",
    "2. Some fields are optional, e.g., you can filter what subset of the full data you want. Only the user data, only the tweet data, or only the place data.\n",
    "\n",
    "```\"user.fields=description,created_at,public_metrics\"```\n",
    "\n",
    "3. One field lets you \"turn the page\" when there are hundreds or thousands of results, because the response bunches results into 500 at a time. The \"next_token\" parameter lets you access the next page of results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Endpoint\n",
    "Now that we have the URL, headers, and parameters we want, we will create a function that will put all of this together and connect to the endpoint.\n",
    "The function below will send the ‚ÄúGET‚Äù request and if everything is correct (response code 200), it will return the response in ‚ÄúJSON‚Äù format.\n",
    "Note: next_token is set to ‚ÄúNone‚Äù by default since we only care about it if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def connect_to_endpoint(url):\n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth,)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all Together\n",
    "Now that we have all the functions we need, let's test putting them all together to create our first request!\n",
    "\n",
    "In the next cell, we will set up our inputs:\n",
    "bearer_token and headers from the API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs for the request\n",
    "bearer_token = auth()\n",
    "users_list = ['pankajtiwari2','NASA']\n",
    "\n",
    "user_fields  = \"user.fields=id,description,created_at,public_metrics,verified,url\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create the URL and get the response from the API.\n",
    "\n",
    "The response returned from the Twitter API is returned in JavaScript Object Notation ‚ÄúJSON‚Äù format.\n",
    "\n",
    "To be able to deal with it and break down the response we get, we will the encoder and decoder that exists for python which we have imported earlier. You can find more information about the library here: https://docs.python.org/3/library/json.html\n",
    "\n",
    "If the returned response from the below code is 200, then the request was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/2/users/by?usernames=pankajtiwari2,NASA&user.fields=id,description,created_at,public_metrics,verified,url\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "url = create_url(users_list,user_fields)\n",
    "json_response = connect_to_endpoint(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print the response in a readable format using this JSON library functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"created_at\": \"2010-07-18T22:49:46.000Z\",\n",
      "            \"description\": \"living in past. want to change the world and create an utopia\",\n",
      "            \"id\": \"168281471\",\n",
      "            \"name\": \"Pankaj Kumar\",\n",
      "            \"public_metrics\": {\n",
      "                \"followers_count\": 63,\n",
      "                \"following_count\": 86,\n",
      "                \"listed_count\": 0,\n",
      "                \"tweet_count\": 155\n",
      "            },\n",
      "            \"url\": \"\",\n",
      "            \"username\": \"pankajtiwari2\",\n",
      "            \"verified\": false\n",
      "        },\n",
      "        {\n",
      "            \"created_at\": \"2007-12-19T20:20:32.000Z\",\n",
      "            \"description\": \"There's space for everybody. \\u2728\",\n",
      "            \"id\": \"11348282\",\n",
      "            \"name\": \"NASA\",\n",
      "            \"public_metrics\": {\n",
      "                \"followers_count\": 50135139,\n",
      "                \"following_count\": 178,\n",
      "                \"listed_count\": 96987,\n",
      "                \"tweet_count\": 67298\n",
      "            },\n",
      "            \"url\": \"https://t.co/9NkQJKAnuU\",\n",
      "            \"username\": \"NASA\",\n",
      "            \"verified\": true\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json_response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the JSON response\n",
    "\n",
    "Now let's break down the returned JSON response.\n",
    "the response is basically read as a Python dictionary and the keys either contain data or contain more dictionaries. The top two keys are:\n",
    "\n",
    "## Data\n",
    "A list of dictionaries, each dictionary represents the data for a tweet. Example on how to retrieve the time from the first tweet was created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2010-07-18T22:49:46.000Z'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response['data'][0]['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(json_response['data'])\n",
    "df.to_csv('handles_to_ids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get timelines for the ids in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/2/users/168281471/tweets\n",
      "200\n",
      "{'data': [{'id': '1459900571746406401', 'text': 'RT @RjSriram15: @AmitShah @narendramodi and many @BJP4India leaders had this question in past on why they‚Äôre not able to consolidate Hindu‚Ä¶'}, {'id': '1457192363726557192', 'text': 'I just published Bitcoins Vs Dollars https://t.co/7kRS36afiI #bitcoin #Dollar #cryptocurrency'}, {'id': '1454682383416901633', 'text': 'I just published Extracting History of #American Revolutionary War Using #NLP https://t.co/RKXujyqf7v \\n\\n#python #Data'}, {'id': '1448478046097342466', 'text': 'RT @Nabu: Too much knowledge for the entire humanity? How we are going to handle and its Impacts. by @pankajtiwari2 (my photo) https://t.co‚Ä¶'}, {'id': '1446640472621867008', 'text': 'RT @DrMichaelHENG1: Too much knowledge for the entire humanity? How we are going to handle and its Impacts. by @pankajtiwari2 https://t.co/‚Ä¶'}, {'id': '1446640363834200066', 'text': \"RT @neo4j: In this week's #twin4j, @pankajtiwari2 utilizes the Twitter API to load data into Neo4j. He analyzes how to use hashtags to answ‚Ä¶\"}, {'id': '1446466816151154690', 'text': 'I just published Too much #knowledge for the entire #humanity ? How we are going to handle and its Impacts. https://t.co/0gd5FzfIgD'}, {'id': '1443178912360513544', 'text': 'I just published Our World Vision of Historic Periods: Too Clear or Too Blur https://t.co/5ygLn4RzKh'}, {'id': '1442853171903307790', 'text': 'I just published Most Downloaded #Python Packages In 2021 Using #Google #BigQuery https://t.co/B5CV94jOYB \\n\\n#programming'}, {'id': '1441662176280809478', 'text': '@Javedakhtarjadu @AnupamPKher ‡§µ‡•à‡§Æ‡§æ‡§®‡§ø‡§ï ‡§™‡§ø‡§õ‡§°‡§º‡§æ‡§™‡§® ‡§ï‡•à‡§∏‡§æ ‡§∞‡§π‡•á‡§ó‡§æ :)'}], 'meta': {'oldest_id': '1441662176280809478', 'newest_id': '1459900571746406401', 'result_count': 10, 'next_token': '7140dibdnow9c7btw3z2gc15948q1vfbhmf3olvlvxtmg'}}\n",
      "https://api.twitter.com/2/users/11348282/tweets\n",
      "200\n",
      "{'data': [{'id': '1466931563514445826', 'text': 'Astronauts Kayla Barron &amp; @AstroMarshburn installed an antenna during a spacewalk, @VP Harris chaired her first National Space Council meeting, and applications opened for new flight directors at @NASA_Johnson. \\n\\nThese stories &amp; more this week at NASA: https://t.co/7hQNER6zkz https://t.co/uFcE7Gpv6R'}, {'id': '1466909093814480896', 'text': 'RT @NASAUniverse: From @chandraxray to our newest mission, IXPE, @NASA_Marshall‚Äôs Martin Weisskopf has spent his career exploring the X-ray‚Ä¶'}, {'id': '1466906239355572224', 'text': 'Launches, lasers &amp; livestreams: Oh my!\\n\\nOn Dec. 5 at 3:30 a.m. (08:30 UTC), join us to watch the launch of our Laser Communications Relay Demonstration aboard a @ULALaunch rocket. #LCRD will showcase revolutionary capabilities of optical communications: https://t.co/BzK1UVsXxr https://t.co/ihA4QOhMy1'}, {'id': '1466896393038180354', 'text': \"RT @Commercial_Crew: We're seeking up to three additional crew flights to the @Space_Station from @SpaceX as part of our Commercial Crew Tr‚Ä¶\"}, {'id': '1466885235241594884', 'text': \"Are you in Antarctica? It's cool if you're not. You can still enjoy the only total #SolarEclipse of 2021 on Dec. 4. Watch it LIVE: https://t.co/HH1sEaccXd\\n\\n‚Ä¢ Broadcast starts at 1:30am ET (06:30 UTC)\\n‚Ä¢ Totality occurs at 2:44am ET (07:44 UTC)\\n\\nüì∏: @NASAHQPhoto\"}, {'id': '1466876820968595461', 'text': '@_Yassiir @Space_Station Our educational resources are available for everyone around the world! Take a look: https://t.co/5BGy7wPIQs'}, {'id': '1466876761786961922', 'text': '@TSwizzl36132625 Our first #LCRD experiments will send data through the complete LCRD relay system, from California to Hawaii. This milestone is expected no earlier than March of 2022.'}, {'id': '1466874446472527876', 'text': \"@k_guarez @NASAArtemis We're glad to hear it! We also have plenty of other books and resources for students on our @NASASTEM page: https://t.co/5BGy7wPIQs\"}, {'id': '1466868894405218313', 'text': \"@MissedFlush @Space_Station We sure do! Here's a recent status check from when we launched #LucyMission to the Trojan asteroids earlier this fall with our partners @ULAlaunch: https://t.co/h1gX0QyJmU\"}, {'id': '1466845860176744455', 'text': \"RT @NASASun: Follow our #SolarTour to hear some big news from Parker Solar Probe! üöÄ\\n\\nStarting tomorrow, Dec. 3, we'll lift off from Earth f‚Ä¶\"}], 'meta': {'oldest_id': '1466845860176744455', 'newest_id': '1466931563514445826', 'result_count': 10, 'next_token': '7140dibdnow9c7btw3z3axx9bq72arpphnvkmoi3acgmt'}}\n"
     ]
    }
   ],
   "source": [
    "tweet_dataset = pd.DataFrame()\n",
    "for id in df['id']:\n",
    "    url = create_url_id(id)\n",
    "    json_response = connect_to_endpoint(url)\n",
    "    print(json_response)\n",
    "    df = pd.DataFrame(json_response['data'])\n",
    "    tweet_dataset = pd.concat([tweet_dataset, df], ignore_index=True)\n",
    "\n",
    "tweet_dataset.to_csv('alltweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
