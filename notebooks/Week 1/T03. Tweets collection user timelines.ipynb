{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CACTUS Week 1\n",
    "\n",
    "https://developer.twitter.com/en/docs/twitter-api/tweets/timelines/api-reference/get-users-id-tweets\n",
    "\n",
    "In order to collect users' timelines, we need their \"id\" from their handle. \n",
    "\n",
    "The first step in the notebook is to collect all the ids for a list of Twitter handles. \n",
    "\n",
    "The second step is to pass the ids one by one and collect all the tweets. These are stored in a dataframe.\n",
    "\n",
    "## Import essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code thanks to https://python.plainenglish.io/using-python-and-twitter-api-2-to-get-user-details-437e442b4be9\n",
    "\n",
    "\n",
    "# For sending GET requests from the API\n",
    "import requests\n",
    "# For saving access tokens and for file management when creating and adding to the dataset\n",
    "import os\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "# For saving the response data in CSV format\n",
    "import csv\n",
    "# For parsing the dates received from twitter in readable formats\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import unicodedata\n",
    "#To add wait time between requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To be able to send your first request to the Twitter API, you need to have a developer account.\n",
    "2. Next, create a project and connect an App through the developer portal.\n",
    "3. Go to the developer portal dashboard\n",
    "4. Sign in with your developer account\n",
    "5. Create a new project, give it a name, a use-case based on the goal you want to achieve, and a description.\n",
    "6. If everything is successful, you should be able to see a page containing your keys and tokens, we will use one of these to access the API. Look out for the BEARER TOKEN. See https://miro.medium.com/max/2400/1*Y20zm9Vf1k5uRMRTMkHRkQ.png\n",
    "\n",
    "7. The next step is to create an auth() function that will have the ‚ÄúBearer Token‚Äù from the app we just created.\n",
    "8. Since this Bearer Token is sensitive information, you should not be sharing it with anyone at all. If you are working with a team you don‚Äôt want anyone to have access to it.\n",
    "9. So, we will save the token in an ‚Äúenvironment variable‚Äù.\n",
    "10. Finally, we will create our auth() function, which retrieves the token from the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKEN'] = ''\n",
    "def auth():\n",
    "    return os.getenv('TOKEN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Headers\n",
    "Next, we will define a function that will take our bearer token, pass it for authorization and return headers we will use to access the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2UserLookupPython\"\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create URL\n",
    "Now that we can access the API, we will build the request for the endpoint we are going to use and the parameters we want to pass.\n",
    "\n",
    "I cannot simply put in \"feedkoko\" and get my tweets.\n",
    "\n",
    "What twitter wants is my numerical ID. so first, i need to make a request to get that number from Twitter\n",
    "\n",
    "Then, i use that number to ask for all my tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# you only have the username so you need the ids\n",
    "def create_url(user_names_list, user_fields ):\n",
    "    # Specify the usernames that you want to lookup below\n",
    "    # You can enter up to 100 comma-separated values.\n",
    "    user_names = ','.join(user_names_list) if len(user_names_list)>1 else user_names_list[0]\n",
    "    \n",
    "    usernames = f\"usernames={user_names}\"\n",
    "    url = \"https://api.twitter.com/2/users/by?{}&{}\".format(usernames, user_fields)\n",
    "    print(url)\n",
    "    return url\n",
    "\n",
    "#once you have the id, you can ask for the tweets\n",
    "def create_url_id(id):\n",
    "    url = \"https://api.twitter.com/2/users/{}/tweets\".format(id)\n",
    "    print(url)\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defined function above contains two pieces:\n",
    "\n",
    "## search_url:\n",
    "\n",
    "Which is the link of the \"endpoint\" we want to access. Endpoint just means.. what we want to do with it. E.g.: if we want all the posts by a user, the endpoint is \"user lookup\"\n",
    "\n",
    "Twitter‚Äôs API has a lot of different endpoints. You can look them up here: https://miro.medium.com/max/700/1*1oJExGGK151WfQJ6LIikww.png\n",
    "\n",
    "Right now, this code is written for the full-archive search endpoint.\n",
    "\n",
    "## query_params:\n",
    "\n",
    "The parameters that the endpoint offers and we can use to customize the request we want to send. E.g.: if we want all the posts by a user, the endpoint is \"user lookup\", and the query parameter is the screen name of the user.\n",
    "\n",
    "1. Some parameters control the returned response\n",
    "```usernames={user_names}```\n",
    "\n",
    "2. Some fields are optional, e.g., you can filter what subset of the full data you want. Only the user data, only the tweet data, or only the place data.\n",
    "\n",
    "```\"user.fields=description,created_at,public_metrics\"```\n",
    "\n",
    "3. One field lets you \"turn the page\" when there are hundreds or thousands of results, because the response bunches results into 500 at a time. The \"next_token\" parameter lets you access the next page of results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Endpoint\n",
    "Now that we have the URL, headers, and parameters we want, we will create a function that will put all of this together and connect to the endpoint.\n",
    "The function below will send the ‚ÄúGET‚Äù request and if everything is correct (response code 200), it will return the response in ‚ÄúJSON‚Äù format.\n",
    "Note: next_token is set to ‚ÄúNone‚Äù by default since we only care about it if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def connect_to_endpoint(url):\n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth,)\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all Together\n",
    "Now that we have all the functions we need, let's test putting them all together to create our first request!\n",
    "\n",
    "In the next cell, we will set up our inputs:\n",
    "bearer_token and headers from the API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs for the request\n",
    "bearer_token = auth()\n",
    "users_list = ['feedkoko','wang_yifei99']\n",
    "\n",
    "user_fields  = \"user.fields=id\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feedkoko', 'wang_yifei99']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 I need to get the id from the username.\n",
    "Now we will create the URL and get the response from the API.\n",
    "\n",
    "The response returned from the Twitter API is returned in JavaScript Object Notation ‚ÄúJSON‚Äù format.\n",
    "\n",
    "To be able to deal with it and break down the response we get, we will the encoder and decoder that exists for python which we have imported earlier. You can find more information about the library here: https://docs.python.org/3/library/json.html\n",
    "\n",
    "If the returned response from the below code is 200, then the request was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/2/users/by?usernames=feedkoko,wang_yifei99&user.fields=id\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "url = create_url(users_list,user_fields)\n",
    "json_response = connect_to_endpoint(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets print the response in a readable format using this JSON library functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"id\": \"34570530\",\n",
      "            \"name\": \"K0k!l J\",\n",
      "            \"username\": \"feedkoko\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"1090085655961493504\",\n",
      "            \"name\": \"Wang Yifei\",\n",
      "            \"username\": \"wang_yifei99\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(json_response, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the JSON response\n",
    "\n",
    "Now let's break down the returned JSON response.\n",
    "the response is basically read as a Python dictionary and the keys either contain data or contain more dictionaries. The top two keys are:\n",
    "\n",
    "## Data\n",
    "A list of dictionaries, each dictionary represents the data for a tweet. Example on how to retrieve the time from the first tweet was created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34570530'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response['data'][0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34570530</td>\n",
       "      <td>K0k!l J</td>\n",
       "      <td>feedkoko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1090085655961493504</td>\n",
       "      <td>Wang Yifei</td>\n",
       "      <td>wang_yifei99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id        name      username\n",
       "0             34570530     K0k!l J      feedkoko\n",
       "1  1090085655961493504  Wang Yifei  wang_yifei99"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(json_response['data'])\n",
    "df.to_csv('handles_to_ids.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get timelines for the ids in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/2/users/34570530/tweets\n",
      "200\n",
      "{'data': [{'id': '1469120936431390720', 'text': 'RT @ashton1anderson: Thrilled to share our paper, out today in @nature, which proposes a new paradigm for the analysis of online platforms‚Ä¶'}, {'id': '1469120294614802432', 'text': '@andyguess @PNASNews @ChrisTokita wow cant wait to read! congrats!'}, {'id': '1469120250356453379', 'text': 'RT @andyguess: Really happy with this new study @PNASNews (with dream team @ChrisTokita and Corina Tarnita) on the information ecosystem an‚Ä¶'}, {'id': '1469120138481831939', 'text': 'RT @j_a_tucker: üì¢üì¢üì¢A bipartisan group of senators announced legislation today to require social media platforms share data with outside, in‚Ä¶'}, {'id': '1469100947318083591', 'text': \"RT @JudeAtwood: TILDA SWINTON AS LIBRARIES: a thread\\n\\nTilda Swinton as Texas Southern University's Library Learning Center https://t.co/jqS‚Ä¶\"}, {'id': '1469087379218591744', 'text': 'RT @jcdl2022: Call for Late-breaking results, Preliminary work, Datasets, Demos #jcdl2022 \\nhttps://t.co/CrIQMmOQ9b\\n\\nThis is a novel track @‚Ä¶'}, {'id': '1468807573096714240', 'text': 'RT @alvinyxz: A Change of Twitter Profile\\n\\nI am humbled to announce that I‚Äôll be joining @UMN_HSJMC next fall as an assistant professor to‚Ä¶'}, {'id': '1468604702375874562', 'text': '@usmantm i was very disappointed when I found out how unromantic your day job is :( on the bright side, maybe thats the secret!'}, {'id': '1468256246125850628', 'text': \"RT @shelbygrossman: This episode inspired me to look at Zoom's transparency reports. Scroll to the bottom and you can actually download a d‚Ä¶\"}, {'id': '1468160242739384322', 'text': 'RT @JurgenPfeffer: Thank you @suhemparack for this great introduction to Tweetpy + Twitter API v2. And of course, thanks to the #tweepy com‚Ä¶'}], 'meta': {'oldest_id': '1468160242739384322', 'newest_id': '1469120936431390720', 'result_count': 10, 'next_token': '7140dibdnow9c7btw3z3b24m6eo0z2oc75lgo4iwak27m'}}\n",
      "https://api.twitter.com/2/users/1090085655961493504/tweets\n",
      "200\n",
      "{'data': [{'id': '1461900447673815042', 'text': 'notoriously unstable‚Ä¶ https://t.co/oXgLosSJuv'}, {'id': '1461900354551881729', 'text': 'RT @Chri5tianGoebel: Difficult times for those of us who use #weibo to study the development of discourses and other topics that rely on hi‚Ä¶'}, {'id': '1460888263133052928', 'text': 'RT @apsrjournal: How do electoral incentives influence politician behavior, specifically when forcing them to anticipate reelection bids? I‚Ä¶'}, {'id': '1460045698359971845', 'text': 'RT @GretaThunberg: Now as #COP26\\xa0 is coming to an end, beware of a tsunami of greenwashing and media spin to somehow frame the outcome as ‚Äú‚Ä¶'}, {'id': '1455555208067440643', 'text': 'So true. Can‚Äôt agree more https://t.co/7nepXBCped'}, {'id': '1454242411320803333', 'text': 'RT @dvshah: Grateful to have been part of the monthlong Emerging Scholars program with @TaliaStroud @s_soroka @kreissdaniel @cmcilwain @dfr‚Ä¶'}, {'id': '1453186679427108864', 'text': 'RT @adjiboussodieng: If you are a student, get a personal website. Please.\\n\\nGithub pages is good. A simple one-pager with resume, contact,‚Ä¶'}, {'id': '1451880102321483778', 'text': 'RT @JulissaMuniz13: If you grew up low income, what‚Äôs the most middle class thing you do these days?‚Ä¶'}, {'id': '1451879681511211016', 'text': \"RT @natematias: Things I didn't expect about academia as an undergrad: the further along you get, the *more* things you apply to.\"}, {'id': '1451350423797862426', 'text': 'RT @dannagal: For over 15 years, every time I teach framing, I return to this glaring example.  Biases infiltrate media content and have th‚Ä¶'}], 'meta': {'oldest_id': '1451350423797862426', 'newest_id': '1461900447673815042', 'result_count': 10, 'next_token': '7140dibdnow9c7btw3z2vhm6rd2j4urih81maqhixprue'}}\n"
     ]
    }
   ],
   "source": [
    "tweet_dataset = pd.DataFrame()\n",
    "for id in df['id']:\n",
    "    url = create_url_id(id)\n",
    "    json_response = connect_to_endpoint(url)\n",
    "    print(json_response)\n",
    "    df = pd.DataFrame(json_response['data'])\n",
    "    tweet_dataset = pd.concat([tweet_dataset, df], ignore_index=True)\n",
    "\n",
    "tweet_dataset.to_csv('alltweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
